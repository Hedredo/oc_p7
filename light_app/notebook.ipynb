{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InstrumentationKey=bc15d784-6826-402f-8984-e505b080cf18;IngestionEndpoint=https://westeurope-5.in.applicationinsights.azure.com/;LiveEndpoint=https://westeurope.livediagnostics.monitor.azure.com/;ApplicationId=dfaf4a4a-47f2-4043-b83a-1b02a56c1dbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 11:30:27.035 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-20 11:30:27.121 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/hedredo/miniconda310/envs/light_p7/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-12-20 11:30:27.122 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-20 11:30:27.123 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-20 11:30:27.123 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-20 11:30:27.124 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-20 11:30:27.124 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-20 11:30:27.125 Session state does not function when running a script without `streamlit run`\n",
      "2024-12-20 11:30:27.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-20 11:30:27.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-20 11:30:27.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-20 11:30:27.127 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-20 11:30:27.127 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-20 11:30:27.127 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-20 11:30:27.128 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from opentelemetry import trace\n",
    "\n",
    "# Configure la connexion à Application Insights\n",
    "connection_string = \"InstrumentationKey=bc15d784-6826-402f-8984-e505b080cf18;IngestionEndpoint=https://westeurope-5.in.applicationinsights.azure.com/;LiveEndpoint=https://westeurope.livediagnostics.monitor.azure.com/;ApplicationId=dfaf4a4a-47f2-4043-b83a-1b02a56c1dbc\"\n",
    "configure_azure_monitor(connection_string=connection_string)\n",
    "\n",
    "# Obtenir un tracer\n",
    "tracer = trace.get_tracer(__name__)\n",
    "\n",
    "# Configure l'url de l'API sur Azure\n",
    "domain = \"hedredo-sentiment-b4a8fabydkh4hge5.westeurope-01.azurewebsites.net\"\n",
    "st.title(\"Live Tweet Sentiment Analysis\")\n",
    "text = st.text_input(\"Enter a tweet please: \")\n",
    "\n",
    "if st.button(\"Predict the sentiment\"):\n",
    "    url = f\"https://{domain}/predict\"\n",
    "    data = {\"tweet\": text}\n",
    "    response = requests.post(url, json=data)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        st.error(\n",
    "            \"Error occurred during prediction. Please verify your input as a text and try again.\"\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        prediction = response.json()[\"sentiment\"]\n",
    "        # Display the result\n",
    "        st.write(f\"Tweet entered: {text}\")\n",
    "        st.write(\"Model computing the sentiment of the tweet...\")\n",
    "        time.sleep(1)\n",
    "        # Display the result\n",
    "        match prediction:\n",
    "            case \"positive\":\n",
    "                st.success(f\"Sentiment predicted: {prediction}\")\n",
    "            case \"negative\":\n",
    "                st.error(f\"Sentiment predicted: {prediction}\")\n",
    "            case _:\n",
    "                st.write(f\"Sentiment predicted: {prediction}\")\n",
    "\n",
    "        # Ajoute une demande d'approbation par l'utilisateur de la prédiction\n",
    "        validation = st.radio(\"Is the prediction seems correct to you?\", (\"Yes\", \"No\"))\n",
    "\n",
    "        # Envoie une trace à Application Insights si l'utilisateur n'approuve la prédiction\n",
    "        if validation == \"No\":\n",
    "            with tracer.start_as_current_span(\"IncorrectPrediction\"):\n",
    "                trace.get_current_span().add_event(\n",
    "                    \"User indicated an invalid prediction\",\n",
    "                    {\"prediction\": prediction, \"tweet\": text},\n",
    "                )\n",
    "                st.info(\n",
    "                    \"Thank you for your feedback. It will be used to improve the model.\"\n",
    "                )\n",
    "        else:\n",
    "            st.info(\"Thank you for your feedback.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from pydantic import BaseModel\n",
    "from fastapi import FastAPI\n",
    "from model import predict_sentiment\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "# Create a Pydantic model to validate the request body\n",
    "class TextData(BaseModel):\n",
    "    text: str\n",
    "\n",
    "\n",
    "# Define a GET endpoint for the root URL\n",
    "@app.get(\"/\")\n",
    "def read_root() -> Union[dict, str]:\n",
    "    return {\"message\": \"Welcome to the Sentiment Analysis API!\"}\n",
    "\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(data: TextData) -> dict:\n",
    "    text = data.text\n",
    "    sentiment = predict_sentiment(text)\n",
    "    return {\"sentiment\": sentiment}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pos_pattern = r\"good|happy|nice|excellent|positive|fortunate|correct|superior|great|positive|superb|wonderful|awesome|fantastic|terrific|amazing|incredible|fabulous|marvelous|excellent|outstanding|exceptional|perfect|pleasing|delightful|pleasurable|satisfying|acceptable|agreeable|enjoyable|favorable|good|gratifying|great|pleasing|positive\"\n",
    "# Compile the regular expression pattern into a regular expression object\n",
    "pos_re = re.compile(pos_pattern, re.IGNORECASE)\n",
    "neg_pattern = r\"bad|unhappy|horrible|negative|unfortunate|wrong|inferior|poor|negative|dreadful|terrible|awful|atrocious|abysmal|appalling|dreadful|lousy|unsatisfactory|unacceptable|disagreeable|displeasing|unfavorable|unpleasant|bad|disgusting|distasteful|foul|gross|nasty|nauseating|obnoxious|offensive|repellent|repulsive|revolting|vile|wretched|bad|disagree\"\n",
    "neg_re = re.compile(neg_pattern, re.IGNORECASE)\n",
    "\n",
    "\n",
    "def predict_sentiment(text: str) -> str:\n",
    "    # Count the number of positive and negative words in the input\n",
    "    pos_count = len(pos_re.findall(text))\n",
    "    neg_count = len(re.findall(neg_re, text))\n",
    "    # Compute the sentiment score\n",
    "    sentiment_score = pos_count - neg_count\n",
    "    # Match the sentiment score to a sentiment category\n",
    "    if sentiment_score > 0:\n",
    "        label = \"positive\"\n",
    "    elif sentiment_score < 0:\n",
    "        label = \"negative\"\n",
    "    else:\n",
    "        label = \"neutral\"\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am very happy with the service. It was excellent.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredict_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m, in \u001b[0;36mpredict_sentiment\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_sentiment\u001b[39m(text):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Count the number of positive and negative words in the input\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     pos_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mpos_re\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m     neg_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(re\u001b[38;5;241m.\u001b[39mfindall(neg_re, text))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Compute the sentiment score\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "predict_sentiment(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "light_p7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
