{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 18:15:29.036627: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-04 18:15:30.533981: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdirectml.d6f03b303ac3c4f2eeb8ca631688c9757b361310.so\n",
      "2025-01-04 18:15:30.534038: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdxcore.so\n",
      "2025-01-04 18:15:30.539965: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libd3d12.so\n",
      "Dropped Escape call with ulEscapeCode : 0x03007703\n",
      "Dropped Escape call with ulEscapeCode : 0x03007703\n",
      "2025-01-04 18:15:31.117510: I tensorflow/c/logging.cc:34] DirectML device enumeration: found 1 compatible adapters.\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "import mlflow.sklearn\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors\n",
    "from huggingface_hub import hf_hub_download\n",
    "from gensim.models import KeyedVectors\n",
    "from tensorflow.config import list_physical_devices\n",
    "from utils import (\n",
    "    split_data,\n",
    "    load_splits_from_parquet,\n",
    "    to_tensorflow_dataset,\n",
    "    create_tf_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear custom objects in case of re-import\n",
    "tf.keras.utils.get_custom_objects().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable(\n",
    "    package=\"custom_text_func\", name=\"custom_standardization\"\n",
    ")\n",
    "def custom_standardization(tensor):\n",
    "    tensor = tf.strings.lower(tensor)  # lowercase\n",
    "    tensor = tf.strings.regex_replace(tensor, r\"@\\w+\", \" \")  # strip mentions\n",
    "    tensor = tf.strings.regex_replace(tensor, r\"http\\S+|www\\S+\", \" \")  # strip urls\n",
    "    tensor = tf.strings.regex_replace(tensor, r\"[^\\w\\s\\d]\", \" \")  # strip punctuation\n",
    "    tensor = tf.strings.regex_replace(tensor, r\"\\s{2,}\", \" \")  # strip multiple spaces\n",
    "    return tf.strings.strip(tensor)  # strip leading and trailing spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 314\n",
    "# Define the URI of the MLflow server and the name of the experiment\n",
    "URI = \"http://localhost:5000\"\n",
    "PATH_PARQUET = \"../data/processed/df_preprocessed.parquet\"\n",
    "PATH_COLS = \"../data/processed/columns.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 314\n",
      "Tensorflow framework: GPU is available\n"
     ]
    }
   ],
   "source": [
    "# Remove FutureWarning alerts\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Initialiser tqdm pour pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Set a random seed\n",
    "SEED = 314\n",
    "np.random.seed(SEED)\n",
    "print(\"Random seed set to\", SEED)\n",
    "\n",
    "# Check if GPU and CUDA are available\n",
    "gpu = list_physical_devices(\"GPU\")\n",
    "print(\"Tensorflow framework: GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target', 'hour_sin', 'hour_cos', 'text', 'text_cleaned', 'text_cleaned_lemma', 'text_cleaned_stem', 'text_cleaned_lemma_nostop', 'text_cleaned_stem_nostop']\n"
     ]
    }
   ],
   "source": [
    "# Load the pickle file containing the columns\n",
    "with open(PATH_COLS, \"rb\") as f:\n",
    "    cols = pickle.load(f)\n",
    "\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1596630 entries, 0 to 799999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count    Dtype  \n",
      "---  ------                     --------------    -----  \n",
      " 0   target                     1596630 non-null  int8   \n",
      " 1   hour_sin                   1596630 non-null  float64\n",
      " 2   hour_cos                   1596630 non-null  float64\n",
      " 3   text                       1596630 non-null  object \n",
      " 4   text_cleaned               1596630 non-null  object \n",
      " 5   text_cleaned_lemma         1596630 non-null  object \n",
      " 6   text_cleaned_stem          1596630 non-null  object \n",
      " 7   text_cleaned_lemma_nostop  1596630 non-null  object \n",
      " 8   text_cleaned_stem_nostop   1596630 non-null  object \n",
      "dtypes: float64(2), int8(1), object(6)\n",
      "memory usage: 111.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\n",
    "    PATH_PARQUET,\n",
    "    engine=\"pyarrow\",\n",
    "    use_nullable_dtypes=False,\n",
    ")\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Séparation des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the split\n",
    "proportion = 1\n",
    "sampling = True\n",
    "test_split = 0.2\n",
    "cols_tracked = [\"text_cleaned\"]\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    df,\n",
    "    test_split=test_split,\n",
    "    sampling=sampling,\n",
    "    proportion=proportion,\n",
    ")\n",
    "# Filter the columns tracked\n",
    "X_train, X_test = load_splits_from_parquet(X_train, X_test, cols_tracked, PATH_PARQUET)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
