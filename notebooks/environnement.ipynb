{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 16:29:36.614368: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-29 16:29:38.085780: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdirectml.d6f03b303ac3c4f2eeb8ca631688c9757b361310.so\n",
      "2024-12-29 16:29:38.085848: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdxcore.so\n",
      "2024-12-29 16:29:38.090556: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libd3d12.so\n",
      "Dropped Escape call with ulEscapeCode : 0x03007703\n",
      "Dropped Escape call with ulEscapeCode : 0x03007703\n",
      "2024-12-29 16:29:38.690265: I tensorflow/c/logging.cc:34] DirectML device enumeration: found 1 compatible adapters.\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "import mlflow.sklearn\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors\n",
    "from huggingface_hub import hf_hub_download\n",
    "from gensim.models import KeyedVectors\n",
    "from tensorflow.config import list_physical_devices\n",
    "from utils import (\n",
    "    split_data,\n",
    "    load_splits_from_parquet,\n",
    "    to_tensorflow_dataset,\n",
    "    create_tf_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear custom objects in case of re-import\n",
    "tf.keras.utils.get_custom_objects().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable(\n",
    "    package=\"custom_text_func\", name=\"custom_standardization\"\n",
    ")\n",
    "def custom_standardization(tensor):\n",
    "    tensor = tf.strings.lower(tensor)  # lowercase\n",
    "    tensor = tf.strings.regex_replace(tensor, r\"@\\w+\", \" \")  # strip mentions\n",
    "    tensor = tf.strings.regex_replace(tensor, r\"http\\S+|www\\S+\", \" \")  # strip urls\n",
    "    tensor = tf.strings.regex_replace(tensor, r\"[^\\w\\s\\d]\", \" \")  # strip punctuation\n",
    "    tensor = tf.strings.regex_replace(tensor, r\"\\s{2,}\", \" \")  # strip multiple spaces\n",
    "    return tf.strings.strip(tensor)  # strip leading and trailing spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 314\n",
    "# Define the URI of the MLflow server and the name of the experiment\n",
    "URI = \"http://localhost:5000\"\n",
    "PATH_PARQUET = \"../data/processed/df_preprocessed.parquet\"\n",
    "PATH_COLS = \"../data/processed/columns.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 314\n",
      "Tensorflow framework: GPU is available\n"
     ]
    }
   ],
   "source": [
    "# Remove FutureWarning alerts\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Initialiser tqdm pour pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Set a random seed\n",
    "SEED = 314\n",
    "np.random.seed(SEED)\n",
    "print(\"Random seed set to\", SEED)\n",
    "\n",
    "# Check if GPU and CUDA are available\n",
    "gpu = list_physical_devices(\"GPU\")\n",
    "print(\"Tensorflow framework: GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Index(['hour', 'target', 'text', 'tokenizer with lowercase',\n",
      "       'tokenizer with lowercase, handle stripping, and length reduction',\n",
      "       'tokenizer with lowercase and alpha',\n",
      "       'tokenizer with lowercase, alpha and emoji',\n",
      "       'tokenizer with lowercase, alpha, and no stop words',\n",
      "       'tokenizer with lowercase, alpha and emoji, and no stop words'],\n",
      "      dtype='object'), array([2, 0, 1, 3, 4, 5, 6, 7, 8]))\n"
     ]
    }
   ],
   "source": [
    "# Load the pickle file containing the columns\n",
    "with open(PATH_COLS, \"rb\") as f:\n",
    "    cols = pickle.load(f)\n",
    "\n",
    "# reorder the columns in cols moving the column after hour column\n",
    "cols = cols.reindex([\"hour\", \"target\", \"text\", *cols[3:]])\n",
    "\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1596630 entries, 0 to 799999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   text    1596630 non-null  object\n",
      " 1   target  1596630 non-null  int8  \n",
      "dtypes: int8(1), object(1)\n",
      "memory usage: 25.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\n",
    "    PATH_PARQUET,\n",
    "    columns=[\"text\", \"target\"],\n",
    "    engine=\"pyarrow\",\n",
    "    use_nullable_dtypes=False,\n",
    ")\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Séparation des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319326,) (79832,) (319326,) (79832,)\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters for the split\n",
    "proportion = 0.25\n",
    "sampling = True\n",
    "test_split = 0.2\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    df,\n",
    "    test_split=test_split,\n",
    "    sampling=sampling,\n",
    "    proportion=proportion,\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
